{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 4 - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing these crappy friggin' batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We open them up with a typical linesplit...\n",
    "file = open(\"task_4_data.txt\", \"r\")\n",
    "batches = file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eyr:2029 iyr:2013',\n",
       " 'hcl:#ceb3a1 byr:1939 ecl:blu',\n",
       " 'hgt:163cm',\n",
       " 'pid:660456119',\n",
       " '',\n",
       " 'hcl:#0f8b2e ecl:grn',\n",
       " 'byr:1975 iyr:2011',\n",
       " 'eyr:2028 cid:207 hgt:158cm',\n",
       " 'pid:755567813',\n",
       " '']"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ...only to find a useless mess. Great.\n",
    "batches[0:10]\n",
    "## Separators are indicated by whitespaces. We can work with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Based on the white-space-separators, we'll make a list of sub-lists, which are separated by the white-spaces. We'll call these sub-lists 'chunks in the loop'\n",
    "batch_list = []\n",
    "batch_list_chunk = []\n",
    "\n",
    "for doc_element in batches:\n",
    "    if doc_element != \"\":\n",
    "        batch_list_chunk.append(doc_element)\n",
    "    else:\n",
    "        batch_list.append(batch_list_chunk)\n",
    "        batch_list_chunk = []\n",
    "batch_list.append(batch_list_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eyr:2029 iyr:2013',\n",
       "  'hcl:#ceb3a1 byr:1939 ecl:blu',\n",
       "  'hgt:163cm',\n",
       "  'pid:660456119'],\n",
       " ['hcl:#0f8b2e ecl:grn',\n",
       "  'byr:1975 iyr:2011',\n",
       "  'eyr:2028 cid:207 hgt:158cm',\n",
       "  'pid:755567813']]"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Getting there...\n",
    "batch_list[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All we need to do is get separators for each document registration per sublist\n",
    "ellist = []\n",
    "doclist = []\n",
    "for i in range(0, len(batch_list)):\n",
    "    ellist = []\n",
    "    for element in batch_list[i]:\n",
    "        ellist = ellist + element.split(\" \")  \n",
    "    doclist.append(ellist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 204 valid documents have been found. Good stuff!\n"
     ]
    }
   ],
   "source": [
    "### Time to start validating!\n",
    "validity_counter = 0\n",
    "valid_docs = []\n",
    "for i in range(0, len(doclist)):\n",
    "    if sum((list(req_doc in doc for req_doc in required_docs for doc in doclist[i]))) == len(required_docs):\n",
    "        valid_docs.append(doclist[i])\n",
    "        validity_counter += 1\n",
    "        \n",
    "print(\"\\n\", validity_counter, \"valid documents have been found. Good stuff!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 4 - Part 2 - also known as hell itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function will turn my pretty lists into marginally pretty dictionaries\n",
    "def list_to_dict(list_of_doom):\n",
    "    list_iter = iter(list_of_doom)\n",
    "    list_dict_object = itertools.zip_longest(list_iter, list_iter, fillvalue=None)\n",
    "    list_dict = dict(list_dict_object)\n",
    "    return(list_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next, we'll define our validation specifications based on some regex that took me at least an hour to come up with.\n",
    "validation_specs = {\n",
    "    \"byr\":\"^(19[2-9][0-9]|200[0-2])$\",\n",
    "    \"eyr\":\"^(202[0-9]|2030)$\",\n",
    "    \"iyr\":\"^(201[0-9]|2020)$\",\n",
    "    \"hgt\":\"^((1[5-8][0-9]|19[0-3])cm)|^((59|6[0-9]|7[0-6])in)$\",\n",
    "    \"hcl\":\"^#[0-9a-f]{6}$\",\n",
    "    \"ecl\":\"^(amb|blu|brn|gry|grn|hzl|oth)$\",\n",
    "    \"pid\":\"^[0-9]{9}$\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found a total of 179 valid passports. By the way, is it just me or are there a LOT of people trying to board flights using illegal documents this scenario?!\n"
     ]
    }
   ],
   "source": [
    "### We'll make two variables: One to indicate the number of valid passports; another to keep track of the number of specifications met.\n",
    "valid_passports = 0\n",
    "spec_counter = 0\n",
    "\n",
    "## For each passport in the validated documents made in part 1 of the this little task of mindmangling horror (which is a good thing, mind you!)...\n",
    "for passport in valid_docs:\n",
    "    # We set out specification_counter to 0\n",
    "    spec_counter = 0\n",
    "    \n",
    "    # Split up our list further, so that we can make ourselves a nice dictionary out of the previous passport-list.\n",
    "    for string in passport: \n",
    "        split_passport = split_passport + string.split(\":\")\n",
    "    # Which is what we're doing here.\n",
    "    passport_dict = list_to_dict(split_passport)\n",
    "    \n",
    "    # Now for each key in the passport dictionary (e.g. \"pid\":)\n",
    "    for key in passport_dict.keys():        \n",
    "        if key != \"cid\":\n",
    "            if re.match(validation_specs[key], passport_dict[key]):\n",
    "                spec_counter += 1\n",
    "    if spec_counter == len(validation_specs):\n",
    "        valid_passports += 1\n",
    "            \n",
    "print(\"We found a total of\", valid_passports, \"valid passports! By the way, is it just me or are there a LOT of people trying to board flights using illegal documents in this scenario?!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
